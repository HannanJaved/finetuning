# Model arguments
model_name_or_path: /scratch/project_462000353/zosaelai2/huggingface/alignment-handbook/data/openeurollm-datamix-2b-en-90pct-SFT-tulu3
torch_dtype: bfloat16
attn_implementation: flash_attention_2

# Data training arguments
dataset_mixture:
  datasets:                     
    - id: /scratch/project_462000353/posttraining_data/DPOTrainer_format/eng/nvidia/HelpSteer3-general
      split: train 
      config: default    
      columns:
        - chosen
        - rejected
        - prompt
      weight: 1.0
dataset_num_proc: 5
# DPO trainer config
bf16: true
do_eval: false
eval_strategy: 'no'
gradient_accumulation_steps: 2
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: true
output_dir: data/openeurollm-datamix-2b-en-90pct-DPO-HelpSteer3
run_name: openeurollm-en-90pct-DPO-HelpSteer3

# hub_strategy: every_save
learning_rate: 5.0e-07
log_level: info
logging_steps: 1
logging_strategy: steps
lr_scheduler_type: cosine_with_min_lr
lr_scheduler_kwargs:
  min_lr_rate: 0.1
max_grad_norm: 0.2
beta: 0.05
loss_type: sigmoid # default for DPO
max_length: 2048
num_train_epochs: 3
overwrite_output_dir: false
per_device_train_batch_size: 1
# push_to_hub: true
padding_free: true
# report_to:
# - wandb
save_strategy: steps
save_steps: 100
save_total_limit: 1
seed: 42
# use_liger_kernel: true
warmup_ratio: 0.1